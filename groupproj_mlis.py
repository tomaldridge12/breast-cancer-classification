# -*- coding: utf-8 -*-
"""GroupProj-MLiS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14HmKtBrEulCO8qwTQVp9aA7g1a46AtWD
"""

from pandas import read_csv, Series, DataFrame
from numpy import ones, matmul, log, where, exp, mean, arange, random
import matplotlib.pyplot as plt
from numpy.linalg import inv, LinAlgError
from json import dumps
from datetime import datetime
from os import path, mkdir
from seaborn import color_palette

# -------------[START]---------------
# -----   DEFINE:  PARAMETERS   -----
# -----------------------------------
percentageOfDataForTraining = False # Set to False (boolean) to loop through all possible train:test datasplits, from 0:100 to 100:0. 
numberOfTrials = 2 # Number of random trials to run the model for. int64
# seeds = [1,2,3]  # int64
fillDataGapsWith = False  # Set to False (boolean) to have rows with gaps completely removed; set to True (boolean) to supplement data gaps with feature averages; Enter a numerical value to replace all data gaps with this number.
verbose = True # (boolean) Enable/Disable additional comments.
scalingFactor = 10^5 # The value that the dataset will be scaled up by to avoid rounding errors and production of singular matrices. 
# -----------------------------------
# -----   DEFINE:  PARAMETERS   -----
# -------------[END]-----------------

# -------------[START]---------------
# -----    NESTED  FUNCTIONS    -----
# -----------------------------------
def getAllData():
    """
    Retrieve all rows of data from Wisconsin dataset (stored remotely) and their respective column names (stored remotely).

    :param (global) fillDataGapsWith: this value will replace data gaps (eg. "?"). Set to False (boolean) for rows with gaps to be removed entirely.
    :return: DataFrame of all rows of data, with named columns and an initial column of ones.
    """ 
   
    columnNames = read_csv('https://raw.githubusercontent.com/reecehill/MLiS/main/breast-cancer-wisconsin-names.csv',
                       header=None).iloc[0].to_numpy() # get column names and convert to nd.array

    allData = read_csv('https://raw.githubusercontent.com/reecehill/MLiS/main/breast-cancer-wisconsin.csv',
                   header=None, # use the first row as data (we add column names next)
                   names=columnNames, # labelled by columnNames
                   usecols=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], # import all columns
                   na_values=["?"], # convert ? values to NaN
                   dtype='float64' # ensure dtype=float64 to allow for NaN
                   )

    if(fillDataGapsWith is False):
      # Remove rows if they are missing any data.
        allData = allData.dropna()
    elif(fillDataGapsWith is True):
      # Keep all rows and replace missing data with that column's mean.
        allData = allData.fillna(allData.mean())
    elif(fillDataGaphsWith is "max"):
        allData = allData.fillna(allData.max())
    elif(fillDataGaphsWith is "min"):
        allData = allData.fillna(allData.min())
    else:
      # Keep all rows and replace missing data with fillDataGrapsWith 
        allData = allData.fillna(fillDataGapsWith)

    allData = allData * (scalingFactor)
    # Add a column of ones as per machine-learning standards    
    allData.insert(loc=0, column='ColumnOfOnes', value=1.0)

    def rewriteClassesRule(row):
      """
      Redefine cells in "Class" column for use in sigmoid function later, changing 2 to -1 and 4 to 1.
      
      :param row: data row current under inspection.
      :return: new cell data
      """ 
      if(row['Class'] == 4* (scalingFactor)):
        val = 1.0  # Malignant
      elif (row['Class'] == 2* (scalingFactor)):
        val = -1   # Benign
      else:
        val = 0  # Inconclusive
      return val

    # Rewrite cells of "Class" column 
    allData["Class"] = allData.apply(rewriteClassesRule, axis=1)

    if(verbose==True):
        print("Total number of records: "+str(len(allData)))
    return allData

def produceGraphics(allData):
    """
    Produces box plots and bar charts in .svg format, saved to local disk. 

    :param allData: wisconsin dataset, without split, without X and Y separation. 
    :param directoryName (global): the directory in which outputted files are saved.
    :return: None
    """ 
    # --- Plot and save dsitribution of features
    allData.drop(['ColumnOfOnes', 'Class'], axis=1).plot(kind='box',subplots=True, layout=(3, 3), sharex=False, sharey=False, figsize=(9, 9))
    savefig(directoryName+'/distribution-of-features.svg')

    # --- Plot box plot to show distribution of features by class
    fig, ax = plt.subplots(nrows=3, ncols=3, sharey=True, figsize=(20, 20))
    subplots = allData.divide(scalingFactor).drop(['ColumnOfOnes'], axis=1).boxplot(ax=ax, by="Class", grid=False, patch_artist=True,boxprops = dict(facecolor=color_palette("Set2")[0], color="black", fill=True), whiskerprops=dict(color='black'), medianprops=dict(color='black', linewidth=3))
 
    for subplot in subplots:
        subplot.set_xlabel('')
        subplot.set_xticklabels(['Benign', 'Malignant'])

    fig.suptitle('Box-plots showing distribution of features by class')
    fig.subplots_adjust(hspace=0.2, wspace=0.05)
    savefig(directoryName+'/distribution-of-features-by-class.svg')


    # --- Plot and save bar chart showing frequency of features per class.
    featuresList = list(allData.drop(['ColumnOfOnes','Class'], axis=1).columns)
    featureValues = list(range(1,10 +1)) # The min and max values for each feature
    frequencyOfMalignancyByFeature = dict.fromkeys(featuresList, [])
    frequencyOfMalignancyPerValueByFeature = dict.fromkeys(featureValues, [])

    # -- Prepare data according to pandas bar plot spec.
    for feature in featuresList: # Loop through clump thickness, mitoses etc... 
        frequenciesByFeature = []
        for featureValue in featureValues: # Loop through their scale (1 to 10)
            filteredRows = allData.apply(lambda x : True if (x['Class'] == float(1.0) and x[feature] == (featureValue * (scalingFactor))) else False, axis = 1) # Find malignant cases per scale value
            frequency = len(filteredRows[filteredRows == True].index) # Get number of rows where malignant
            frequenciesByFeature.append(frequency) # Add to array from other 
        frequencyOfMalignancyByFeature[feature] = frequenciesByFeature
    
    input('Press enter to generate bar plots of malignancy frequency per feature...')
    subplots = DataFrame(frequencyOfMalignancyByFeature, index=featureValues).plot(kind='bar', subplots=True, xlabel="", layout=(3, 3), sharex=True, sharey=True, figsize=(9, 9), legend=False)
    savefig(directoryName+'/features-to-class1.svg')
    
def changeSeed(currentSeed):
    if(verbose==True):
        print("Changing seed #"+str(seed)+" as it generates singular matrix. An additional seed has been added in its place. Press enter to continue.") 
        input("Press Enter to continue anyway.")
    lastSeedValue = seeds[-1]
    seeds.remove(seed)
    seeds.append(lastSeedValue + 1)

def stratifyAndRandomlySample(allData, seed, percentageOfDataForTraining):
    """
    Stratify all data based on their Class. Then, randomly sample (according to seed) to produce training-testing dataset split of user-defined proportions. 

    :param allData: wisconsin dataset, without split. 
    :param seed: controls the random sampling to allow reproducibility
    :param percentageOfDataForTraining: defines the size (in percentage) of allData that should be exclusively used for training. The testing dataset will use what remains. 
    :param (global) fillDataGapsWith: this value will replace data gaps (eg. "?"). Set to False (boolean) for rows with gaps to be removed entirely.
    :return: DataFrame of all rows of data, with named columns and an initial column of ones.
    """ 

    # -- PRODUCE TRAINING DATASET
    groupedTrainDatum = allData.groupby(
        'Class', # Stratify by class
        group_keys=False)

    trainDatum = groupedTrainDatum.apply(
            lambda x:
            x.sample(
                frac=(percentageOfDataForTraining/100), # Take percentage of entire dataset
                random_state=int(seed) # Seed
                )
    )

    # -- PRODUCE TESTING DATASET
    testDatum = allData.drop(trainDatum.index)
    
    # -- SPLIT TRAINING DATA INTO X (FEATURES) AND Y (TARGET)
    trainDatumY = trainDatum.Class
    trainDatumX = trainDatum.drop(
        'Class', axis=1, inplace=False)
    del trainDatum

    # -- SPLIT TESTING DATA INTO X (FEATURES) AND Y (TARGET)
    testDatumY = testDatum.Class
    testDatumX = testDatum.drop(
        'Class', axis=1, inplace=False)
    del testDatum
    if(verbose==True):
        print('trainDatumX:')
        print(trainDatumX.to_numpy(dtype='float64'))
        print("Number of records (training): "+str(len(trainDatumX)))
        print("Number of records (testing): "+str(len(testDatumX)))
    return trainDatumX, trainDatumY, testDatumX, testDatumY


def calculateOptimalBeta(trainDatumX, trainDatumY):
    """
    Use principles of linear model to find the optimal values for Beta (B*).
    Equation defined: B* = ((X^T * X) ^-1 ) * X^T * Y

    :param trainDatumX: features of training set
    :param trainDatumY: target of training set 
    :return: ndarray for beta
    """ 
    if(verbose==True):
        print(trainDatumY)
    Xt = trainDatumX.T
    if(verbose==True):
        print('---Xt:')
        print(Xt)
    XtX = matmul(Xt, trainDatumX)
    if(verbose==True):
        print('---XtX:')
        print(XtX)
    XtY = matmul(Xt, trainDatumY)
    if(verbose==True):
        print('---XtY:')
        print(XtY)
    invXtX = inv(XtX)
    if(verbose==True):
        print('---inv(XtX):')
        print(invXtX)
    optimalBeta = matmul(invXtX, XtY)
    
    if(verbose==True):
        print('B* = ', optimalBeta)
    return optimalBeta


def computePredictions(optimalBeta, trainDatumX):
    """
    Apply optimalBeta to features (X) of training data to get predicted Y values. 
    
    :param optimalBeta: optimal beta values
    :param trainDatumX: features of training set  
    :return: predicted Y values, scaled (by sigmoid function) to be between 0 and 1 
    """ 
    def applySigmoidToPredictions(predictedYValue):
      return 1 / (1 + exp(-predictedYValue))
  
    predictedYValue = matmul(trainDatumX.to_numpy(), optimalBeta) # y^ = X*beta
    predictedYValue = applySigmoidToPredictions(predictedYValue) # p = sig(y^)
    return predictedYValue

def classifyPredictions(predictedYValues):
    """
    Convert predicted Y values (between 0 and 1) into binary classifications of malignant (if y^ > 0.5), benign (if y^ < 0.5), inconclusive (otherwise).
    
    :param predictedYValues: predicted Y values, scaled (by sigmoid function) to be between 0 and 1   
    :return: predicted Y classes 
    """ 
    def classifyRule(row):
        """
        Redefine rows of data Series, predictedYValues, using 0.5 as a threshold.

        :param row: data row current under inspection.
        :return: data Series of -1.0, 0.0, and 1.0. Each representing a class.
        """ 
        if(row > 0.5): 
            val = 1.0  #Set class to Malignant
        elif row < 0.5: 
            val = -1.0  #Set class to Benign
        else: 
        # Given this may be significant, we ensure it isn't unnoticed by waiting for user input.
            print("WARNING: The sequence has generated a prediction that is inconclusive.")
            if(verbose==True):
                input("Press Enter to continue anyway.")
            else:
                print("Continuing anyway. (To change this behaviour, set verbose to true")
            val = 0.0 #Set class to Inconclusive
        return val

    predictedYValues = Series(predictedYValues).apply(classifyRule)
    if (verbose==True):
        print("Y^ =", predictedYValues)
        print("Y^ (classified): ", predictedYValues.to_numpy())
    return predictedYValues.to_numpy()

def calculateStats(predictedYClass, trainDatumY):
    """
    Calculate performance metrics of mode.

    :param predictedYClass: predicted classes (target, Y)
    :param trainDatumY: actual classes of known data 
    :return: negativeLogLikehood, accuracy, precision, sensitivity, specificity
    """ 
    truePositives = where((predictedYClass == 1.0) &
                          (trainDatumY == 1.0))[0].size
    falsePositives = where((predictedYClass == 1.0) &
                           (trainDatumY == -1.0))[0].size
    trueNegatives = where((predictedYClass == -1.0) &
                          (trainDatumY == -1.0))[0].size
    falseNegatives = where((predictedYClass == -1.0) &
                           (trainDatumY == 1.0))[0].size
    
    # Negative log likelihood (NLL) = Negative mean of [ Y*BtX - log(1 + exp(BtX))]
    negativeLogLikelihood = -mean((trainDatumY*predictedYClass) - log(1+exp(predictedYClass)))

    
    if (truePositives + trueNegatives > 0):
        accuracy = (truePositives + trueNegatives) / trainDatumY.size
    else:
        accuracy = 0
    if truePositives > 0:
        precision  = truePositives / (truePositives + falsePositives)
        sensitivity = truePositives / (truePositives + falseNegatives)
    else:
        precision = 0
        sensitivity = 0
    
    if trueNegatives > 0:
        specificity = trueNegatives / (trueNegatives + falsePositives)
    else:
        specificity = 0

    return negativeLogLikelihood, accuracy, precision, sensitivity, specificity

def produceSequenceReport(negativeLogLikelihood, accuracy, precision, sensitivity, specificity):
    """
    Store performance metrics in a sequence-specific dictionary, sequenceReport.
    For definitions of parameters, consult function calculateStats.
    :return: sequenceReport
    """ 
    
    sequenceReport = {
        'NLL': negativeLogLikelihood,
        'Accuracy': accuracy,
        'Precision': precision,
        'Sensitivity': sensitivity,
        'Specificity': specificity,
    }
    return sequenceReport

def addSequenceReportToTotalReport(sequenceReport, reportOfTotals):
    """
    Store sequence-specific performance metrics to a running tally of totals, a dictionary.
    For definitions of parameters, consult function calculateStats.

    :return: newReportOfTotals (a temporary variable)
    """
    newReportOfTotals = {
        'NLL': reportOfTotals['NLL'] + sequenceReport['NLL'],
        'Accuracy': reportOfTotals['Accuracy'] + sequenceReport['Accuracy'],
        'Precision': reportOfTotals['Precision'] + sequenceReport['Precision'],
        'Sensitivity': reportOfTotals['Sensitivity'] + sequenceReport['Sensitivity'],
        'Specificity': reportOfTotals['Specificity'] + sequenceReport['Specificity'],
    }
    return newReportOfTotals

def storeAveragesReportToCsv(averagesReport):
    """
    Store final report of averaged performance metrics, averagesReport, to a csv file for plotting later.
    :param averageReport: dictionary of 5 keys, see produceSequenceReport(), that are averaged from all seed trials for a given train-test data split. 
    :param directoryName (global): name of directory (current timestamp) to which records will be saved. 
    :param seeds (global): list of current seeds in use, to differentiate simulations of different len(seeds)
    :return: None
    """ 
    seedLength = len(seeds)
    filePath = directoryName+'/'+str(seedLength)+'-seeds.csv'
    if path.isfile(filePath):
        mode = 'a'
        header = 0
    else:
        mode = 'w'
        header = averagesReport.keys()
    
    # Add current train:test data split information to report, before adding to csv
    averagesReport['Training Set Size'] = percentageOfDataForTraining
    averagesReport['Testing Set Size'] = 100-percentageOfDataForTraining
    DataFrame({'>': averagesReport}).transpose().to_csv(filePath, header=header, mode=mode)

def runSequence(optimalBeta, knownDataX, knownDataY, reportOfTotals = False):
    """
    Main orchestrator of prediction process.
    Use the given features (knownDataX) and optimalBeta to make predictions. Then, compare these predictions against knownDataY to check if correct.
    Upon completion, store results in a sequence-specific report, and to a running-tally report, reportOfTotals. 

    :param optimalBeta: optimal values for Beta
    :knownDataX: features taken from either training or testing sub-set.
    :knownDataY: known targets taken from either training or testing sub-set.
    :reportOfTotals: the running-tally report to which the sequence-specific report should be added. Specify "False" (boolean) to not add a sequence-specific report (i.e., when training) 
    :return: sequenceReport (consult function produceSequenceReport), and conditionally, reportOfTotals (consult addSequenceReportToTotalReport) 
    """
    predictedYValues = computePredictions(optimalBeta, knownDataX)
    predictedYClasses = classifyPredictions(predictedYValues)
    negativeLogLikelihood, accuracy, precision, sensitivity, specificity = calculateStats(predictedYClasses, knownDataY)
    sequenceReport = produceSequenceReport(negativeLogLikelihood, accuracy, precision, sensitivity, specificity)
    if(reportOfTotals is not False):
      reportOfTotals = addSequenceReportToTotalReport(sequenceReport, reportOfTotals)
      return sequenceReport, reportOfTotals
    else:
      return sequenceReport


# -----    NESTED  FUNCTIONS    -----
# -------------[END]-----------------

# -------------[START]---------------
# -----        MAIN BODY        -----
# -----------------------------------

# -- PREPARE DIRECTORY FOR OUTPUT
directoryName = datetime.now().strftime("%Y%m%d-%H%M%S")
mkdir(directoryName)

# -- PREPARE SEEDS
startSeedingFrom = 10
seedUntil = startSeedingFrom+numberOfTrials;
seeds = list(range(startSeedingFrom,seedUntil))
seedLength = len(seeds)

# -- GET ALL DATA
allData = getAllData()

# -- PRODUCE AND EXPORT GRAPHS OF DATA
produceGraphics(allData)

input("Press enter to begin simulating through the seeds...")

allReports = {'splits': {}}

# -- PREPARE FOR LOOPING THROUGH TRAIN:TEST SPLITS
if percentageOfDataForTraining is not False:
    percentagesOfDataForTraining=[percentageOfDataForTraining] # User has requested one split, so only run this single split.
else:
    numberOfRows = len(allData)
    increment = 100/numberOfRows
    startIncrementingFrom = 0
    continueIncrementingUntil = 100 # Ensure we increment to include 100%
    percentagesOfDataForTraining= arange(startIncrementingFrom,continueIncrementingUntil,increment)


# ------ MAIN LOOPS [START]------
for percentageOfDataForTraining in percentagesOfDataForTraining:
    reportOfTotals = {
        "NLL": 0,
        "Accuracy": 0,
        "Precision": 0,
        "Sensitivity": 0,
        "Specificity": 0,
    }
    splitReport = {'seeds': {}, 'Average Metrics': reportOfTotals}
    for seed in seeds:
        if(verbose==True):
            print('\r\n---\r\n*** STARTING SEED #'+str(seed))

        # -- SPLIT DATA FOR TRAINING AND TESTING
        trainDatumX, trainDatumY, testDatumX, testDatumY = stratifyAndRandomlySample(
            allData, seed, percentageOfDataForTraining)
        
        # -- USING TRAINING DATASET
        if(verbose==True):
            print('\r\n---\r\n** Commencing: TRAINING')

        try:
            optimalBeta = calculateOptimalBeta(trainDatumX.to_numpy(), trainDatumY)
        except LinAlgError:
            # This sample of data leads to a matrix that cannot be inversed, so resample.
            changeSeed(seed)
            continue


        seedReportForTraining = runSequence(optimalBeta, knownDataX = trainDatumX, knownDataY = trainDatumY, reportOfTotals=False)
        if(verbose==True):
            print('\r\n---\r\n** ** Finished: TRAINING')


        # -- USING TESTING DATASET
        if(verbose==True):
            print('\r\n---\r\n** Commencing: TESTING')
        seedReportForTesting, reportOfTotals = runSequence(optimalBeta, knownDataX = testDatumX, knownDataY = testDatumY, reportOfTotals=reportOfTotals)
        if(verbose==True):
            print('\r\n---\r\n** Finished: TESTING')
        
        # -- STORE PERFORMANCE TRAINING AND TESTING REPORTS TO "splitReport"
        splitReport['seeds'].update({
            seed: {
            'Training': seedReportForTraining,
            'Testing': seedReportForTesting
            }
            })
    

    # ------  ADD TO AVERAGES REPORT  ------
    averagesReport = {
        'Mean NLL': (reportOfTotals['NLL'] / seedLength), # NLL is NOT expressed as a percentage
        'Mean Accuracy': str((reportOfTotals['Accuracy'] / seedLength) * 100)+'%',
        'Mean Precision': str((reportOfTotals['Precision'] / seedLength) * 100)+'%',
        'Mean Sensitivity': str((reportOfTotals['Sensitivity'] / seedLength) * 100)+'%',
        'Mean Specificity': str((reportOfTotals['Specificity'] / seedLength) * 100)+'%',
        }
    splitReport['Average Metrics'].update(averagesReport)
    storeAveragesReportToCsv(averagesReport)
    
    # ------  ADD TO FINAL REPORT  ------
    allReports['splits'].update({
            percentageOfDataForTraining: splitReport
            })
    
# ----------------------------

# ------  PRINT FINISH  ------
if(verbose==True):
    print(dumps(allReports, indent=4))
    print('\r\n---\r\nFinished.\r\n---\r\nAlongside generated graphics, a final report is available in the folder, "'+str(directoryName)+'".\r\n---\r\n')
else:
    print('\r\n---\r\nFinished.\r\n---\r\nAlongside generated graphics, a final report is available in the folder, "'+str(directoryName)+'".\r\n---\r\nYou can set verbose to true to increase verbosity.')
# ----------------------------


# -----        MAIN BODY        -----
# -------------[END]-----------------

# CODE FOR PLOTTING PERFORMANCE GRAPHS

import seaborn as sns
removeData100Seeds = pd.read_csv('100-seeds-removed.csv') # Read data from file - 100 seeds, all training splits, remove NAN
# Set defaults for plots
#sns.set_style('white') # darkgrid, white grid, dark, white and ticks
plt.rc('axes', titlesize=10)  
plt.rc('axes', labelsize=8)  
plt.rc('xtick', labelsize=13)    
plt.rc('ytick', labelsize=13)
matplotlib.rcParams['lines.linewidth'] = 1.0 
#plt.rc('legend', fontsize=13)


# ---------- PLOTS FOR REMOVED DATA -------------
fig = plt.figure()
ax = fig.add_axes([0,2.5,1,0.3])
ax1 = fig.add_axes([0,2,1,0.3])
ax2 = fig.add_axes([0,1.5,1,0.3])
ax3 = fig.add_axes([0,1,1,0.3])
ax4 = fig.add_axes([0,0.5,1,0.3])


ax.plot(removeData100Seeds['Training Set Size'], 
        removeData100Seeds['Mean Accuracy']*100,
        label='Removed'
        ,color = sns.color_palette('Set2')[0])
ax1.plot(removeData100Seeds['Training Set Size'], 
        removeData100Seeds['Mean Precision']*100,
        label='Removed'
        ,color = sns.color_palette('Set2')[0])
ax2.plot(removeData100Seeds['Training Set Size'], 
        removeData100Seeds['Mean Sensitivity']*100,
        label='Removed'
        ,color = sns.color_palette('Set2')[0])
ax3.plot(removeData100Seeds['Training Set Size'], 
        removeData100Seeds['Mean Specificity']*100,
        label='Removed'
        ,color = sns.color_palette('Set2')[0])
ax4.plot(removeData100Seeds['Training Set Size'], 
        removeData100Seeds['Mean NLL'],
        label='Removed'
        ,color = sns.color_palette('Set2')[0])
ax.set_xlim(0,100)
ax.set_ylim(90,100)

ax.set_xlabel('Training Set Size (as % of total data))', labelpad=10)
ax.set_ylabel('Performance (%)', labelpad=10)
ax.set_title('Mean Accuracy')

# --------- PLOTS FOR REPLACED WITH MEAN DATA ------------
meanData100Seeds = pd.read_csv('100-seeds-mean.csv')
ax.plot(meanData100Seeds['Training Set Size'], 
        meanData100Seeds['Mean Accuracy']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[1])
ax1.plot(meanData100Seeds['Training Set Size'], 
        meanData100Seeds['Mean Precision']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[1])
ax2.plot(meanData100Seeds['Training Set Size'], 
        meanData100Seeds['Mean Sensitivity']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[1])
ax3.plot(meanData100Seeds['Training Set Size'], 
        meanData100Seeds['Mean Specificity']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[1])
ax4.plot(meanData100Seeds['Training Set Size'], 
        meanData100Seeds['Mean NLL'],
        label='Mean'
        ,color = sns.color_palette('Set2')[1])

# --------- PLOTS FOR REPLACED WITH 1 ------------
v1Data100Seeds = pd.read_csv('100-seeds-1.csv')

ax.plot(v1Data100Seeds['Training Set Size'], 
        v1Data100Seeds['Mean Accuracy']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[2])
ax1.plot(v1Data100Seeds['Training Set Size'], 
        v1Data100Seeds['Mean Precision']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[2])
ax2.plot(v1Data100Seeds['Training Set Size'], 
        v1Data100Seeds['Mean Sensitivity']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[2])
ax3.plot(v1Data100Seeds['Training Set Size'], 
        v1Data100Seeds['Mean Specificity']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[2])
ax4.plot(v1Data100Seeds['Training Set Size'], 
        v1Data100Seeds['Mean NLL'],
        label='Mean'
        ,color = sns.color_palette('Set2')[2])

# --------- PLOTS FOR REPLACED WITH MAX DATA ------------
maxData100Seeds = pd.read_csv('100-seeds-max.csv')
ax.plot(maxData100Seeds['Training Set Size'], 
        maxData100Seeds['Mean Accuracy']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[3])
ax1.plot(maxData100Seeds['Training Set Size'], 
        maxData100Seeds['Mean Precision']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[3])
ax2.plot(maxData100Seeds['Training Set Size'], 
        maxData100Seeds['Mean Sensitivity']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[3])
ax3.plot(maxData100Seeds['Training Set Size'], 
        maxData100Seeds['Mean Specificity']*100,
        label='Mean'
        ,color = sns.color_palette('Set2')[3])
ax4.plot(maxData100Seeds['Training Set Size'], 
        maxData100Seeds['Mean NLL'],
        label='Mean'
        ,color = sns.color_palette('Set2')[3],
         linewidth=1)

ax1.set_xlim(0,100)
ax1.set_ylim(90,100)
ax1.set_xlabel('Training Set Size (as % of total data))', labelpad=10)
ax1.set_ylabel('Performance (%)', labelpad=10)
ax1.set_title('Mean Precision')



ax2.set_xlim(0,100)
ax2.set_ylim(85,95)
ax2.set_xlabel('Training Set Size (as % of total data))', labelpad=10)
ax2.set_ylabel('Performance (%)', labelpad=10)
ax2.set_title('Mean Sensitivity')


ax3.set_xlim(0,100)
ax3.set_ylim(90,100)
ax3.set_xlabel('Training Set Size (as % of total data))', labelpad=10)
ax3.set_ylabel('Performance (%)', labelpad=10)
ax3.set_title('Mean Specificity')

ax4.set_xlim(0,100)
ax4.set_ylim(0.5,-0.5)
ax4.set_xlabel('Training Set Size (as % of total data))', labelpad=10)
ax4.set_ylabel('Performance (%)', labelpad=10)
ax4.set_title('Mean Negative Log Likelihood')

plt.savefig("results.png", dpi = 300, bbox_inches = "tight")
files.download("results.png")

"""<h2>
TO-DO: Main aim is to iterate through every possible test:train split to find the optimal value. To do this we will:
</h2>
<ul>
<li> Iterate through every possible value of the training split. This is stored as a percentage.
<ul>
<li>There are 699 rows in the data, meaning each row contributes 1/699 to the percentage. This makes us want to iterate from 0 to 100, going up by 100/699 each time until we have finished iterating. **NOTE: I have made calculation of 699 dynamic, to allow for removal of rows if data gaps.**</li>
</ul>

<li> Store the output for each of these splits into a vector
<ul><li>
We could also store every metric for each training split (what resolution do we want this at? Every single split, or only integer values?) to allow for a plot of each metric based off split !! TALKING POINT !!
</ul>
<li> Keep track of the optimal training:test split, where we define output as our "favourite" metric when averaged over X training splits.
<ul><li>
Either just find max(accuracy)[index], i.e. the index (split) that provided the best accuracy or store maxAccuracy in a variable, compare each iteration, if higher then rewrite maxAccuracy and store this index (split) in another variable. First method seems more appropriate, if possible.
</ul>
<li>
Restructure our report form to accommodate for the new information.
<ul><li> Visualised in our facebook chat, will try to show here (could remove the metrics from each seed and just use average split metrics if it gets way too much (it might, unless verbose == true). We could also output as a JSON file? Not sure if necessary, might be useful for something? You tell me tbh):
<br>
Splits
<br> - Split 1 0.14%
<br> ----- Seed 1
<br> --------- metrics
<br> ----- Seed 2 
<br> --------- metrics
<br> ----- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...
<br> ----- Seed N 
<br> --------- metrics
<br> ----- Size of training split (could be put in split title? See above)
<br> ----- Metrics for split
<br>
<br> - Split 2 0.28%
<br> ----- Seed 1
<br> --------- metrics
<br> ----- Seed 2
<br> --------- metrics
<br> ----- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...
<br> ----- Seed N
<br> --------- metrics
<br> ----- Size of training split (could be put in split title? See above)
<br> ----- Metrics for split
<br>
<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...
<br>
<br> - Split M 99.86%
<br> ----- Seed 1
<br> --------- metrics
<br> ----- Seed 2
<br> --------- metrics
<br> ----- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;...
<br> ----- Seed N
<br> --------- metrics
<br> ----- Size of training split (could be put in split title? See above)
<br> ----- Metrics for split
<br>
<br> - Highest Accuracy Recorded
<br> - Optimal training:test split
</ul>
<li> Plot metrics
<ul><li> Line graphs of metrics with regard to each split
<li> Distribution of data initially (box plots, anything else? See Tom code)


"""

